\documentclass{beamer}

\usepackage[ngerman]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath,amsfonts,amssymb}

\usepackage[absolute,overlay]{textpos}

\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}


\usetheme{Luebeck}
\usecolortheme{orchid}

\title{Seminar Kombinatorische Optimierung: \\ Markov Random Fields}
\author{Jan Lammel}

\begin{document}
	
\frame{\titlepage}

\frame{
	\frametitle{Table of contents}
	\tableofcontents[hideallsubsections]
	
}

\section{Introduction}
\frame{
\frametitle{Introduction}

\begin{textblock}{12}(1,5)
	Until now: \\
	\begin{itemize}
	\item 2 label segmentation (foreground / background)
	\item Efficient via max-flow / min-cut
	\end{itemize}
	
	Now: \\
	\begin{itemize}
	\item Segmentation with arbitrary number of labels
	\item Actual problem is NP-complete
	\item Reduction to small 2-label problems with approximative methods
	\end{itemize}
\end{textblock}
}

\frame{
\frametitle{Introduction}
\todo{Bild + fertige Segmentierung als Motivation was am Ende rauskommen soll.}



}

\section{Mathematical problem formulation}
\subsection{Basic definitions}
\frame{
\frametitle{Basic definitions}

\begin{textblock}{14}(1, 4.5)

	\begin{itemize}
		\item Image consists of pixels $P = \{ 1, 2, ..., m \}$
		\item Segmentation labels $\mathcal{L} = \{l_1,l_ 2, ..., l_k\}$
		\item Each pixel has two statistical values
		\begin{itemize}
			\item hypothesis $f \in \mathcal{L}^m$: \ segmentation label
			\item observation $O$: \qquad \ information in the image (intensities, ...)
		\end{itemize}
	\end{itemize}
	
	\todo{Fehlt noch was wichtiges?!}

\end{textblock}

}

\subsection{Maximum a posteriori (MAP) estimate}
\frame{
\frametitle{Maximum a posteriori (MAP) estimate}

\begin{textblock}{14}(1, 4.5)

\begin{itemize}


\item Objective: $f^* = \arg \max\limits_{f} p(f|O)$ \\

\item Using Bayes' Theorem: $p(f|O) = \frac{p(O|f) p(f)}{p(O)}$ \\

\vspace{0.25cm}

Follows from definition of conditional probabilities: \\
$p(A,B) = p(A|B)p(B) = p(B|A) p(A)$ \\

\vspace{0.5cm}

\item $\Rightarrow f^* = \arg \max\limits_{f} p(O|f)p(f)$ \\

\vspace{0.4cm}

\item We need expressions for \\
	\begin{itemize}
	\item $p(O|f)$ -- \textit{likelihood} 
	\item $p(f)$ -- \textit{prior probability}
	\end{itemize}

\end{itemize}


\end{textblock}

}

\subsection{Markov Random Field (MRF)}
\frame{
\frametitle{Markov Random Fields (MRF)}

\begin{textblock}{7}(0., 4.)
\includegraphics[width=1.15\textwidth]{/home/argo/seminar/mrf1.png}
\end{textblock}


\begin{textblock}{7}(7, 4.5)

\begin{itemize}
\item Condition for an MRF: Each random variable depends on other random variables only through its neighbors: \\

\vspace{0.25cm}

$p(f_p|f_{\mathcal{P} \setminus p}) = p(f_p|f_{\mathcal{N}_p}) $

\vspace{0.25cm}

\item here: neighborhood system are adjacent pixels

\end{itemize}

\end{textblock}

}

\frame{
\frametitle{Markov Random Fields (MRF) -- Prior term}



\begin{textblock}{7}(0., 4.)
\includegraphics[width=1.15\textwidth]{/home/argo/seminar/mrf2.png}
\end{textblock}


\begin{textblock}{9}(7, 5.)

\begin{itemize}
	\item General for Markov Random Fields: \\
	Hammersley-Clifford theorem: $p(f) \propto \exp \{- \sum_C V_C(f) \}$ \\
	$C$: Clique in neighborhood system
	\item Here: $p(f) \propto \exp\{ - \sum\limits_{p \in \mathcal{P}} \sum\limits_{q \in \mathcal{N}_p} V_{pq} (f_p, f_q) \}$
	\item Used for smoothing to penalize different neighboring pixel labels.
\end{itemize}

\end{textblock}

}

\frame{
\frametitle{Markov Random Fields (MRF) -- Data term}





}

\subsection{Multiway Cut Problem}
\frame{blu
}


\section{Approximative Algorithms}
\subsection{$\alpha$-$\beta$ swap}
\subsection{$\alpha$-expansion}

\section{Application example}
\subsection{flute segmentation}



	
	
	
\end{document}