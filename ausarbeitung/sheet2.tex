\documentclass{scrartcl}[12pt, halfparskip]
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath, amssymb, amstext}
\usepackage{wrapfig}



\usepackage{caption}
\usepackage{subcaption}


\title{Seminar Combinatorial Optimization}
\author{Jan Lammel}
\date{\today{}, Heidelberg}



\begin{document}

\maketitle \ \\ 
\newpage


\section{Introduction}
In this work there will be presented the results of Yuri Boykov et al. \cite{boykov98}, \cite{boykov01} to solve computer vision problems like image segmentation. First we will explain the mathematical framework, including the relation to the segmentation vision problem we want to solve. Afterwards two approximative algorithms are introduced in order to solve the problem efficiently. Finally we will show some outcomes of this method on real data.


\section{Mathematics}
Given some random variables called Observations $O$ from input data the final objective is to achieve the hypothesis $f$, which equates the segmentation.


\subsection{Maximum a posteriori (MAP) estimate}

So in the end we want $f$ s.t. $p(f|O)$ is maximized. Using Bayes' rule

\begin{equation}
	p(f|O) \propto p(O|f) p(f)
\end{equation}

means that we need expressions for $p(O|f)$ and $p(f)$.


\subsection{Markov Random Fields (MRFs)}
In computer vision tasks we handle with images containing pixels $P = \{ 1, 2, ..., m \}$. Each of these pixels has two attributes in terms of random variables, observation $O$ and hypothesis $f$. In the task of image segmentation the observation $O$ would be for example the result of normalized correlation (see ...) and $f$ are the labels of the segmentation pattern (see ...). \\

This system of pixels can be drawn as a graph where each pixel is represented by a node. In a Markov Random Field all neighboring pixels are connected with an edge (see ...). Due to the Hammersley-Clifford theorem, which stats that the prior term can be written as sum of potentials in an exponential functions, it holds for our MRF:
\begin{equation}
	p(f) \propto \exp\{ - \sum\limits_{p \in \mathcal{P}} \sum\limits_{q \in \mathcal{N}_p} V_{pq} (f_p, f_q) \}
\end{equation}
where $\mathcal{N}_p$ are the neighboring pixels of $p$ and $V_{pq}$ is the potential between pixel $p$ and $q$. This term is usually used to smooth the solution, i.e. penalize different neighboring labels $f_p \neq f_q$.

Examples for potentials $V$ are
\begin{itemize}
	\item Generalized Potts model: $V_{pq}(f_p, f_q) = u_{pq} (1 - \delta(f_p - f_q))$
	\item Truncated quadratic distance: $V_{pq}(f_p, f_q) = \min (K=const, |f_p - f_q|^2)$
	\item Truncated $L_2$ norm: $V_{pq}(f_p, f_q) = ???$
\end{itemize}

For the data term $p(O|f)$ we are assuming an independend and identical distributed (iid) distribution so we get

\begin{equation}
	p(O|f) = \prod\limits_{p \in \mathcal{P}} g(i, p, f_p)
\end{equation}

where g is ???

Due to the fact that we want to maximize $p(f)$ we can take the negative logarithm and minimize the resultung Energy function

\begin{equation}
E(f) = - \ln(p(f)) = \sum\limits_{p \in \mathcal{P}} \sum\limits_{q \in \mathcal{N}_p} V_{pq} (f_p, f_q) - \sum\limits_{p \in \mathcal{P}} \ln(g(i, p, f_p))
\end{equation}






\subsection{Multiway Cut Problem}

\section{Approximative Algorithms for the Multiway Cut Problem}
\subsection{$\alpha$ - $\beta$ - Swap}
\subsection{$\alpha$-Expansion}

\section{Applications in Vision problems}
\subsection{Image restoration}
\subsection{Segmentation}




\begin{thebibliography}{9}

\bibitem{boykov98}
  Yuri Boykov, Olga Veksler and Ramin Zabih:
  Markov Random Fields with Efficient Approximations,
  1998,
  IEEE Computer Society Conference on Computer Vision and
  Pattern Recognition
  
\bibitem{boykov01}
  Yuri Boykov, Olga Veksler and Ramin Zabih:
  Fast Approximate Energy Minimization via Graph
  Cuts,
  IEEE Transactions on Pattern Analysis and Machine Intelligence archive Volume,
  23 Issue 11, November 2001 Page 1222-1239
  

  

\end{thebibliography}

\end{document}